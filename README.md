# ScAllergen backend and database
![License](https://img.shields.io/badge/license-MIT-blue)

![Version](https://img.shields.io/badge/version-1.0.0-green)
The backend service and database for the ScAllergen application.
## Index
- [Introduction](#introduction)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
## Introduction
ScAllergen is a backend system designed to identify potential allergens in food ingredient lists. It leverages **Neo4j** to store a knowledge graph based on the FoodOn ontology.
Key features include:
- **Knowledge Graph:** Stores relationships between food products (e.g., "Milk" is a parent of "Yogurt").
- **Fuzzy Matching:** Uses `RapidFuzz` and `SentenceTransformers` to map messy input text (e.g., "skimmed mlk") to standardized ontology nodes.
- **Graph Traversal:** Detects hidden allergens by traversing the graph (e.g., detecting "dairy" allergy in "whey protein").
![Project Logo](./docs/images/ScAllergen.png)
### Technologies
- **Language:** Python 3.10+
- **Framework:** FastAPI
- **Database:** Neo4j (Graph Database)
- **Containerization:** Docker & Docker Compose
- **Machine Learning:** Sentence Transformers (all-MiniLM-L6-v2), RapidFuzz

## Installation
Instructions for setting up the development environment.  

### Requirements
- **Docker Desktop** (or Docker Engine + Docker Compose)
- **Git**
  

### Installation steps
1. Clone the repository:

```bash
git clone https://github.com/your-username/scallergen-backend.git
cd scallergen-backend
```

2. Configure Environment Variables:
```
# Neo4j Configuration
NEO4J_URI=bolt://neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_secure_password 

# Ngrok Configuration
NGROK_AUTHTOKEN=your_ngrok_token
```

3. Build and Start the System:
Run the following command to build the images and start the services (Database, Backend, Ngrok):
```
docker compose up -d --build
```

4. Initialize the Database (First Run Only):
The database starts empty. You need to run the **Importer** profile to load the FoodOn OWL file, generate embeddings, and create indexes. This process may take a few minutes.
```
docker compose --profile init up --build setup_importer
```
Wait until the process exits with code 0.

5. Restart Backend:
Once the data is imported, restart the backend to load the new data into the RAM cache.
```
docker compose restart backend
```


## Usage
Once the containers are running, you can access the services via the following endpoints:
**Neo4j Browser (Database Interface):**
- URL: `http://localhost:7474`
- Username: `neo4j`
- Password: (The one you set in `.env`)
**Ngrok Dashboard (Tunnel Inspector):**
- URL: `http://localhost:4040`

### API Endpoints
The API documentation is automatically generated by FastAPI. You can explore it interactively at `http://localhost:8000/docs` once the server is running.
Here is a summary of the available endpoints:

| Method | Endpoint       | Description                                                                                                          |
| :----- | :------------- | :------------------------------------------------------------------------------------------------------------------- |
| `POST` | `/check`       | **Core Feature.** Checks for conflicts between user's allergens and scanned ingredients. Returns safe/unsafe status. |
| `POST` | `/debug/check` | Same as `/check`, but includes detailed debug info (fuzzy scores, reasoning, mapping logic).                         |
| `GET`  | `/node`        | Returns a list of suggested FoodOn nodes based on input text (Useful for Autocomplete/Search bars).                  |
| `GET`  | `/debug/node`  | Inspects exactly how the fuzzy matcher maps a specific text to a Node ID in the database.                            |
| `GET`  | `/`            | Health check to verify if the server is running.                                                                     |

## Project Structure
```
├── database/
│   ├── import/          # Stores the source OWL ontology file
│   ├── neo4j-docker/    # Persisted data for Neo4j (Do not commit)
│   └── setup/           # Python scripts for importing data & training embeddings
├── server/
│   ├── lib/             # Shared libraries (Fuzzy matching, Graph traversal)
│   ├── main.py          # FastAPI application entry point
│   └── requirements.txt # Backend dependencies
├── docker-compose.yml   # Docker orchestration file
└── .env                 # Environment variables
```